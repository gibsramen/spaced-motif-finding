{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_count_mat(dna_list, pseudo = True):\n",
    "    ln = len(dna_list[0])\n",
    "    count_mat = list()\n",
    "    if pseudo:\n",
    "        for i in range(ln):\n",
    "            count_mat.append({\"A\":1, \"C\":1, \"G\":1, \"T\":1})\n",
    "    else:\n",
    "        for i in range(ln):\n",
    "            count_mat.append({\"A\":0, \"C\":0, \"G\":0, \"T\":0})\n",
    "    \n",
    "    for i in range(len(dna_list[0])):\n",
    "        for dna in dna_list:\n",
    "            char = dna[i]\n",
    "            count_mat[i][char] += 1\n",
    "    \n",
    "    return count_mat\n",
    "\n",
    "def score_kmer(kmer, prof_mat):\n",
    "    score = 1\n",
    "    for i in range(len(kmer)):\n",
    "        score *= prof_mat[i][kmer[i]]\n",
    "    return score\n",
    "\n",
    "\n",
    "def gen_prof_mat(dna_list, pseudo = True):\n",
    "    count_mat = gen_count_mat(dna_list, pseudo)\n",
    "    prof_mat = list()\n",
    "    for _, slc_count in enumerate(count_mat):\n",
    "        tot_sum = sum(slc_count.values())\n",
    "        slc_prof = dict()\n",
    "        for key, value in slc_count.items():\n",
    "            slc_prof[key] = value / tot_sum\n",
    "        prof_mat.append(slc_prof)\n",
    "    return prof_mat\n",
    "\n",
    "\n",
    "def gen_all_gapped_kmers(dna, k1, k2, gmin, gmax):\n",
    "    ln = len(dna)\n",
    "    for g in range(gmin, gmax + 1):\n",
    "        for i in range(ln - k1 - k2 - g + 1):\n",
    "            yield dna[i : i + k1] + dna[i + g + 1: i + g + k2 + 1], g\n",
    "\n",
    "\n",
    "def entropy(prof_mat):\n",
    "    entrpy = 0\n",
    "    for column in prof_mat:\n",
    "        for nuc, val in column.items():\n",
    "            if val != 0:\n",
    "                entrpy += (val * math.log2(val))\n",
    "    return -entrpy\n",
    "\n",
    "\n",
    "def gen_prof_most_prob_gapped_kmer(dna, k1, k2, gmin, gmax, prof_mat):\n",
    "    most_prob_kmer = dna[:k1 + k2]\n",
    "    best_score = score_kmer(most_prob_kmer, prof_mat)\n",
    "    best_g = gmin\n",
    "    for kmer, g in gen_all_gapped_kmers(dna, k1, k2, gmin, gmax):\n",
    "        curr_score = score_kmer(kmer, prof_mat)\n",
    "        if curr_score > best_score:\n",
    "            most_prob_kmer = kmer\n",
    "            best_score = curr_score\n",
    "            best_g = g\n",
    "    return most_prob_kmer, best_g\n",
    "\n",
    "\n",
    "\n",
    "# has a bug in storing the best g value, still need to track down\n",
    "def greedy_gapped_motif_search(dna_list, k1, k2, t, gmin, gmax):\n",
    "    \n",
    "    best_motifs = [dna[:k1] + dna[gmin : k2 + gmin] for dna in dna_list]\n",
    "    best_score = entropy(gen_prof_mat(best_motifs))\n",
    "    # the g values are going awry, something is wrong\n",
    "    best_gaps = [gmin for _ in range(len(dna_list))]\n",
    "    \n",
    "    for kmer, g in gen_all_gapped_kmers(dna_list[0], k1, k2, gmin, gmax):\n",
    "        \n",
    "        gapped_motifs = [kmer[:k1] + kmer[-k2:]]\n",
    "        \n",
    "        # could be in the assignment or initialization of the current gaps matrix\n",
    "        gaps = [gmin for _ in range(len(dna_list))]\n",
    "        gaps[0] = g\n",
    "        \n",
    "        for i in range(1, t):\n",
    "            gapped_motif_prof = gen_prof_mat(gapped_motifs)\n",
    "            \n",
    "            # maybe it's not returning the correct values here?\n",
    "            most_prob_kmer, most_prob_g = gen_prof_most_prob_gapped_kmer(dna_list[i], k1, k2,\n",
    "                                                                         gmin, gmax,\n",
    "                                                                         gapped_motif_prof)\n",
    "            \n",
    "            gapped_motifs.append(most_prob_kmer)\n",
    "            # could be here\n",
    "            gaps[i] = most_prob_g\n",
    "            \n",
    "        curr_score = entropy(gen_prof_mat(gapped_motifs))\n",
    "        if curr_score < best_score:\n",
    "            best_score = curr_score\n",
    "            best_motifs = gapped_motifs\n",
    "            # probably not here, though could be shallow vs deep copy???\n",
    "            best_gaps = gaps[:]\n",
    "    \n",
    "    return best_motifs, best_gaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['AGAG', 'AGAG', 'AGAG', 'AGAG'], [3, 4, 3, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expect AGAG with gap lengths of 2, 3, 3, 2 in that order\n",
    "test_strs = [\"ATCGAGCTAGATTTA\", \"AGTTCAGACACACAC\",\n",
    "             \"CAGATAGACGAGTTT\", \"ATAGACAGATAGTTT\"]\n",
    "\n",
    "k1 = 2\n",
    "k2 = 2\n",
    "t = len(test_strs)\n",
    "gmin = 2\n",
    "gmax = 5\n",
    "\n",
    "greedy_gapped_motif_search(test_strs, k1, k2, t, gmin, gmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heck yeah!\n",
    "* We're getting the correct results!  That was super straightforward\n",
    "* Still has a problem with returning the gap lengths, I'll get to that later\n",
    "* Wait for Chien-Ju to make the test cases and get the length bug working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
